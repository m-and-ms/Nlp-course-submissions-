# -*- coding: utf-8 -*-
"""labnlp2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10j_QXHV_sK1LuQciEs-QVkwumfXfihC6
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import spacy
import re
nlp = spacy.load('en')

url = 'http://quotes.toscrape.com/'

new_data=[]    
data=[]   
data = requests.get(url)
soup = BeautifulSoup(data.content, 'html.parser')
for quote in (soup.find_all('div', class_=["quote"])):
        
   data.append({'quotes': quote.find('span', attrs={"itemprop": "text"}).text,'tags': re.sub('\s+',' ',quote.find('div', attrs={"class": "tags"}).text.lstrip().rstrip().replace('\n',' ').strip('Tags:').replace('\t','')).lstrip().replace(' ',',')})
new_data.extend(data)                         

                        
print (new_data)


sim_score={}
df =  pd.DataFrame(new_data)
print(df.head().tags[1].split(','))

def common_elements(list1, list2):
 return list(set(list1) & set(list2))


print (df.tags[2].split(','),df.tags[4].split(','))
print( common_elements(df.tags[2].split(','),df.tags[4].split(',')))
print(len(df.quotes))
#


for i in range(len(df.quotes)):
  for j in range(len(df.quotes)):
    
    if i !=j:  
      if common_elements(df.tags[i].split(','),df.tags[j].split(',')):
        sen1=nlp(df.quotes[i])
        sen2=nlp(df.quotes[j])
        sim=sen1.similarity(sen2)
        sim_score[ str(i) +df.quotes[i]+ "," +str(j)+df.quotes[j]]=sim
      else  :
        s=1
    else :
        s=1;
       
print("hey" ,sim_score)

